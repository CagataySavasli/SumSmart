{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:05.010979Z",
     "start_time": "2024-11-21T13:01:02.873443Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:08.177247Z",
     "start_time": "2024-11-21T13:01:05.011976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(huggingface_dataset_name)"
   ],
   "id": "8f432a5a41d1a920",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:08.181075Z",
     "start_time": "2024-11-21T13:01:08.178263Z"
    }
   },
   "cell_type": "code",
   "source": "peft_model_path=\"./SumSmart-checkpoint-local\"",
   "id": "77b22c8735425092",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:09.805637Z",
     "start_time": "2024-11-21T13:01:08.181941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
    "                                       peft_model_path,\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ],
   "id": "5f9a05bceed3a133",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:09.809290Z",
     "start_time": "2024-11-21T13:01:09.807094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
    "    end_prompt = '\\n\\nSummary: '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example"
   ],
   "id": "b6c1f2db0a48f7b4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:10.402790Z",
     "start_time": "2024-11-21T13:01:09.809936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The dataset actually contains 3 diff splits: train, validation, test.\n",
    "# The tokenize_function code is handling all data across all splits in batches.\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"
   ],
   "id": "ef264699d438ac2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "239259282d8644719bf5b27f60dcd640"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:10.774426Z",
     "start_time": "2024-11-21T13:01:10.403520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)\n",
    "\n",
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "print(tokenized_datasets)"
   ],
   "id": "9c26dbc990d67a57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "523029cb132d4792b74928dd843c2938"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (125, 2)\n",
      "Validation: (5, 2)\n",
      "Test: (15, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 125\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 5\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:15.019610Z",
     "start_time": "2024-11-21T13:01:10.775310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dialogues = dataset['test'][0:10]['dialogue']\n",
    "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
    "original_model_summaries = []\n",
    "instruct_model_summaries = []\n",
    "peft_model_summaries = []\n",
    "\n",
    "for idx, dialogue in enumerate(dialogues):\n",
    "  prompt = f\"\"\"\n",
    "  summarize the following conversation\n",
    "  {dialogue}\n",
    "  Summary:\n",
    "  \"\"\"\n",
    "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "  # Ensure that input_ids and the models are on the same device\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  input_ids = input_ids.to(device)\n",
    "  human_baseline_text_output = human_baseline_summaries[idx]\n",
    "  peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "  peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "  peft_model_summaries.append(peft_model_text_output)"
   ],
   "id": "f0ee18f0659a61f3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T13:01:17.595333Z",
     "start_time": "2024-11-21T13:01:15.020462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "peft_model_results = rouge.compute(\n",
    "    predictions=peft_model_summaries,\n",
    "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "\n",
    "print('PEFT MODEL:')\n",
    "print(peft_model_results)\n"
   ],
   "id": "2eea8dfdb0863c44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efee14a73a374e24b31623301aab5f77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT MODEL:\n",
      "{'rouge1': np.float64(0.0806405672062167), 'rouge2': np.float64(0.004444444444444444), 'rougeL': np.float64(0.07887281974278054), 'rougeLsum': np.float64(0.07910367674505411)}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c9da3b8bedd96165"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
